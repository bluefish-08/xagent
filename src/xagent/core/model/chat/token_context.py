"""Token usage tracking using contextvars.

This module provides a thread-safe way to track token usage across LLM calls
without modifying function signatures. Using contextvars allows the token
statistics to be automatically collected during task execution.
"""

import contextvars
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional


@dataclass
class TokenUsage:
    """Token usage statistics for a task or operation.

    Attributes:
        input_tokens: Number of tokens in prompts sent to LLM
        output_tokens: Number of tokens generated by LLM
        llm_calls: Number of LLM API calls made
        details: Detailed breakdown by model/call type
    """

    input_tokens: int = 0
    output_tokens: int = 0
    llm_calls: int = 0
    details: List[Dict] = field(default_factory=list)

    @property
    def total_tokens(self) -> int:
        """Total tokens used (input + output)."""
        return self.input_tokens + self.output_tokens

    def add_input_tokens(
        self, tokens: int, model: str = "", call_type: str = ""
    ) -> None:
        """Add input tokens from a prompt."""
        self.input_tokens += tokens
        if model or call_type:
            self.details.append(
                {
                    "type": "input",
                    "tokens": tokens,
                    "model": model,
                    "call_type": call_type,
                }
            )

    def add_output_tokens(
        self, tokens: int, model: str = "", call_type: str = ""
    ) -> None:
        """Add output tokens from a completion."""
        self.output_tokens += tokens
        if model or call_type:
            self.details.append(
                {
                    "type": "output",
                    "tokens": tokens,
                    "model": model,
                    "call_type": call_type,
                }
            )

    def increment_llm_calls(self) -> None:
        """Increment the LLM call counter."""
        self.llm_calls += 1

    def merge(self, other: "TokenUsage") -> None:
        """Merge another TokenUsage into this one."""
        self.input_tokens += other.input_tokens
        self.output_tokens += other.output_tokens
        self.llm_calls += other.llm_calls
        self.details.extend(other.details)

    def to_dict(self) -> Dict:
        """Convert to dictionary for serialization."""
        return {
            "input_tokens": self.input_tokens,
            "output_tokens": self.output_tokens,
            "total_tokens": self.total_tokens,
            "llm_calls": self.llm_calls,
            "details": self.details,
        }

    @classmethod
    def from_dict(cls, data: Dict) -> "TokenUsage":
        """Create from dictionary."""
        return cls(
            input_tokens=data.get("input_tokens", 0),
            output_tokens=data.get("output_tokens", 0),
            llm_calls=data.get("llm_calls", 0),
            details=data.get("details", []),
        )


# ContextVar for thread-local token tracking
token_context: contextvars.ContextVar[TokenUsage] = contextvars.ContextVar(
    "token_context", default=TokenUsage()
)


class TokenContextManager:
    """Manager for token context with automatic cleanup.

    Example:
        with TokenContextManager() as manager:
            # LLM calls here will be tracked
            await llm.chat(messages)
        # After exiting, usage can be retrieved
        usage = manager.get_usage()
    """

    def __init__(self, parent_usage: Optional[TokenUsage] = None):
        """Initialize the context manager.

        Args:
            parent_usage: Optional parent TokenUsage to merge into
        """
        self._token_usage = TokenUsage()
        if parent_usage:
            self._token_usage.merge(parent_usage)
        self._previous_token: Optional[TokenUsage] = None

    def __enter__(self) -> "TokenContextManager":
        """Enter the context and start tracking."""
        self._previous_token = token_context.get(None)
        token_context.set(self._token_usage)
        return self

    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
        """Exit the context and restore previous state."""
        if self._previous_token is not None:
            token_context.set(self._previous_token)
        else:
            # Clear the context
            token_context.set(TokenUsage())

    def get_usage(self) -> TokenUsage:
        """Get the current token usage."""
        return self._token_usage

    def add_input_tokens(
        self, tokens: int, model: str = "", call_type: str = ""
    ) -> None:
        """Add input tokens (convenience method)."""
        self._token_usage.add_input_tokens(tokens, model, call_type)

    def add_output_tokens(
        self, tokens: int, model: str = "", call_type: str = ""
    ) -> None:
        """Add output tokens (convenience method)."""
        self._token_usage.add_output_tokens(tokens, model, call_type)


# Global functions for easier access


def get_token_usage() -> TokenUsage:
    """Get the current token usage from context."""
    return token_context.get()


def add_token_usage(
    input_tokens: int = 0,
    output_tokens: int = 0,
    model: str = "",
    call_type: str = "",
) -> None:
    """Add token usage to the current context.

    Args:
        input_tokens: Number of input tokens
        output_tokens: Number of output tokens
        model: Model name for tracking
        call_type: Type of call (chat, stream_chat, vision_chat, etc.)
    """
    usage = token_context.get()
    if input_tokens or output_tokens:
        # Increment LLM call counter for each API call
        usage.increment_llm_calls()
    if input_tokens:
        usage.add_input_tokens(input_tokens, model, call_type)
    if output_tokens:
        usage.add_output_tokens(output_tokens, model, call_type)


def reset_token_usage() -> TokenUsage:
    """Reset and return the current token usage."""
    new_usage = TokenUsage()
    token_context.set(new_usage)
    return new_usage


def get_and_reset_token_usage() -> TokenUsage:
    """Get current usage and reset the context."""
    usage = token_context.get()
    reset_token_usage()
    return usage
